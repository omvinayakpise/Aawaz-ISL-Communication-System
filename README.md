Aawaz is a web communication application that uses a computerâ€™s webcam to capture User1(User 1- Deaf and Mute Person; User 2- Normal Person) signing the sign language alphabet and translate it in real-time as a text and as an audio message in the language required by the User2. It allows the user to create and train his own gesture as well for the convenience of the user. They can train words and assign a gesture for those respective words. To achieve the desired output, we would be implementing 
various techniques of Deep Learning and Computer Vision. For extracting the spatial features from the video stream, we opted for Convolutional Neural Network(CNN), a type of Artificial Neural Network (ANN), which may yield us better results. The output will be displayed in the form of text and audio and for the further convenience of the user.
